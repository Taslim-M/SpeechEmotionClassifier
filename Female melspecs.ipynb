{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter female wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import scipy \n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActorID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Not Hispanic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ActorID  Age     Sex       Race     Ethnicity\n",
       "0     1001   51    Male  Caucasian  Not Hispanic\n",
       "1     1002   21  Female  Caucasian  Not Hispanic\n",
       "2     1003   21  Female  Caucasian  Not Hispanic"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\VideoDemographics.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_ids=[str(df.loc[i].iat[0]) for i in df.index if df.loc[i].iat[2]==\"Female\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_folder_name=r'C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\AudioWAV'\n",
    "dest_folder_name= r'C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\FemaleAudioWAV'\n",
    "file_names = listdir(audio_folder_name)\n",
    "for f in file_names:\n",
    "    \n",
    "    x=f.split(\"_\")\n",
    "    if x[0] not in female_ids:\n",
    "       continue\n",
    "    #print(f)\n",
    "    shutil.move(audio_folder_name + '\\\\' +f, dest_folder_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to mel specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FUNCTIONS\n",
    "\n",
    "def convert_single_audio_to_image(audio_path, image_path, spectrogram_dimensions = (64,64)):\n",
    "    data, sr = librosa.load(audio_path, sr = 22050)  \n",
    "    print(\"sr={}\".format(sr))\n",
    "    #Make a mel spectrogram from audio\n",
    "    window_width =  0.025 #25 ms  window size \n",
    "    sliding = 0.01 #10ms stride \n",
    "    print(\"Length of audio:\", np.size(data,0)/22050)\n",
    "    spec = librosa.feature.melspectrogram(y=data, sr=sr, n_fft = int(window_width*sr), hop_length =int(sliding*sr))\n",
    "    print(spec.shape)\n",
    "    \n",
    "    #Convert amplitude to decibels\n",
    "    db_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    print(db_spec.shape)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    \n",
    "   # fig.set_size_inches((spectrogram_dimensions[0]/fig.get_dpi(), spectrogram_dimensions[1]/fig.get_dpi()))\n",
    "    \n",
    "    #Display final mel spectrogram\n",
    "    librosa.display.specshow(db_spec, sr=sr,x_axis='time',y_axis='mel', hop_length =int(sliding*sr))\n",
    "    plt.colorbar()\n",
    "    fig.savefig(image_path)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of Wav_files in 1= C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\AudioWAV\\sam\n",
      "1001_IEO_ANG_MD.wav\n",
      "sr=22050\n",
      "Length of audio: 2.635963718820862\n",
      "(128, 3)\n",
      "(128, 3)\n",
      "count of Wav_files in 2= C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\AudioWAV\\sam\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    audio_folder_name= r\"C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\AudioWAV\\sam\"\n",
    "    image_folder_name=  r\"C:\\Users\\Tasli\\Desktop\\PythonFolder\\SpeechEmotionClassifier\\cremad\\AudioWAV\\sam\"\n",
    "    file_names = listdir(audio_folder_name)\n",
    "#     file_names = [f for f in listdir(audio_folder_name)]\n",
    "    print(\"count of Wav_files in {}= {}\".format(len(file_names),audio_folder_name))\n",
    "    for file_name in file_names:\n",
    "        name, ext = os.path.splitext(file_name)\n",
    "        print(file_name)\n",
    "            \n",
    "        audio_path = audio_folder_name + '\\\\' + file_name\n",
    "        spectogram_path = image_folder_name + '\\\\' + file_name.replace('.wav', '.png')\n",
    "        convert_single_audio_to_image(audio_path,spectogram_path)\n",
    "    image_files= listdir(image_folder_name)\n",
    "    print(\"count of Wav_files in {}= {}\".format(len(image_files),image_folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
